# Lumina AWS Deployment Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# NVIDIA API Configuration
# =============================================================================
# Get your API key from: https://catalog.ngc.nvidia.com/
# This same key is used for both NIM deployment and backend LLM services
NGC_CLI_API_KEY=nvapi-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
NVIDIA_API_KEY=nvapi-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# =============================================================================
# LLM API Keys (Required for Backend)
# =============================================================================

# Google Gemini API Key for extraction
# Get from: https://makersuite.google.com/app/apikey
GOOGLE_GEMINI_API_KEY=AIzaSyXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

# =============================================================================
# AWS Configuration (Vocareum Lab)
# =============================================================================
# Get these from your Vocareum lab AWS Details
AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
AWS_SESSION_TOKEN=IQoJb3JpZ2luX2VjEHoaCXVzLXdlc3QtMiJHMEUCIQDTGfwhqBxN1E...
AWS_DEFAULT_REGION=us-east-1

# =============================================================================
# Deployment Configuration
# =============================================================================
# EKS Cluster Configuration
CLUSTER_NAME=lumina-nim-cluster
CLUSTER_NODE_TYPE=g6e.xlarge
NODE_COUNT=1

# EC2 Backend Configuration
INSTANCE_TYPE=g5.xlarge
KEY_NAME=lumina-backend-key
SECURITY_GROUP=lumina-backend-sg

# S3 Frontend Configuration
S3_BUCKET_PREFIX=lumina-frontend
FRONTEND_DOMAIN=your-domain.com

# =============================================================================
# Application Configuration
# =============================================================================
# Database Configuration
POSTGRES_PASSWORD=lumina_secure_password_2024
DATABASE_URL=postgresql://lumina:lumina_secure_password_2024@postgres:5432/lumina_db

# Redis Configuration
REDIS_URL=redis://redis:6379

# NIM Model Configuration
NIM_MODEL_NAME=nvidia/llama-3.1-nemotron-nano-8b-v1
NIM_NAMESPACE=nim

# =============================================================================
# Optional Configuration
# =============================================================================
# Deployment Mode (ec2 or lambda)
DEPLOYMENT_MODE=ec2

# Enable debug logging
DEBUG=false

# Custom tags for AWS resources
PROJECT_TAG=lumina-hackathon
ENVIRONMENT_TAG=development

# =============================================================================
# Vocareum Lab Specific Settings
# =============================================================================
# Maximum resources (don't exceed these)
MAX_EC2_INSTANCES=2
MAX_EKS_CLUSTERS=1
MAX_EKS_NODES=2

# Cost monitoring
DAILY_COST_LIMIT=100
ALERT_EMAIL=your-email@example.com